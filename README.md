# House Prices
Este reposit√≥rio foi desenvolvido como parte da avalia√ß√£o da p√≥s-gradua√ß√£o em Ci√™ncia de Dados e Analytics (PUC-Rio).
O objetivo √© prever o pre√ßo de venda de im√≥veis utilizando o conjunto de dados da competi√ß√£o House Prices: Advanced Regression Techniques (Kaggle).

Dados e regras da competi√ß√£o: Kaggle ‚Äì House Prices: Advanced Regression Techniques.

üéØ Objetivo

Construir um pipeline de Machine Learning para estimar o SalePrice a partir de vari√°veis estruturais, de qualidade e localiza√ß√£o, avaliando modelos e comparando resultados com a m√©trica oficial da competi√ß√£o (RMSE do log do pre√ßo).

üóÇÔ∏è Dataset

Train: cont√©m as features e a vari√°vel alvo (SalePrice).

Test: cont√©m apenas as features; as previs√µes s√£o submetidas ao Kaggle. (Resultado: 0.25)

Presen√ßa de dados faltantes, vari√°veis categ√≥ricas, distribui√ß√µes assim√©tricas e outliers.

üîß Metodologia (resumo)

EDA: an√°lise de distribui√ß√£o, correla√ß√µes, detec√ß√£o de outliers e skewness.

Tratamento de nulos: estrat√©gias diferentes para num√©ricas e categ√≥ricas (ex.: imputa√ß√£o constante ou mediana/moda).

Feature engineering (exemplos usuais):

Cria√ß√£o de m√©tricas agregadas de √°rea (ex.: TotalSF), idade do im√≥vel, qualidade combinada etc.

Transforma√ß√µes de log em vari√°veis altamente assim√©tricas (incluindo SalePrice).


Modelagem:

Modelos de baseline (Regress√£o Linear).

Regulariza√ß√£o: Ridge e Lasso.

Modelos de √°rvore: Random Forest, Gradient Boosting (e opcionalmente XGBoost/LightGBM).

Valida√ß√£o:

Cross-validation (K-Fold/StratifiedKFold no log do pre√ßo).

Sele√ß√£o de hiperpar√¢metros via GridSearchCV/RandomizedSearchCV.

Pipeline:

Uso de Pipeline + ColumnTransformer para garantir reprodutibilidade (mesmos passos em treino e teste).

M√©trica:

RMSE do log(SalePrice), alinhada √† avalia√ß√£o do Kaggle.
